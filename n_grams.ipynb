{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "n-grams.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN0L7AiekZdfAzGzneok6E4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Herzeg137/entering-to-NLP/blob/main/n_grams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOoinNY9R7qL"
      },
      "outputs": [],
      "source": [
        "#Step1\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(style='seaborn')\n",
        "\n",
        "df=pd.read_csv('all-data.csv',encoding = \"ISO-8859-1\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "download the csv file [here](https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news)"
      ],
      "metadata": {
        "id": "WujsS5UBUpF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step2\n",
        "df.info()"
      ],
      "metadata": {
        "id": "S7GZZhgyUykJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step3\n",
        "df.isna().sum()\n",
        "df['Sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "vk7UGYekVRS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step4\n",
        "#Column ni nomini o'zgaritish\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/all-data.csv\", encoding = \"ISO-8859-1\" )\n",
        "\n",
        "df.rename(columns={\"neutral\": \"Sentiment\"}, inplace=True)\n",
        "df.rename(columns={\"According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\": \"Headlines\"}, inplace=True)\n",
        "df.columns\n",
        "df.info()"
      ],
      "metadata": {
        "id": "6mnzXrXnVRec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step5\n",
        "#Xususiyatni chiqarish\n",
        "#Sentiment bu Mustqail qiymat\n",
        "#New HEadlines esa Qaram qiymat\n",
        "y=df['Sentiment'].values\n",
        "y.shape"
      ],
      "metadata": {
        "id": "IeGvwNgmaO3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df['Headlines'].values\n",
        "x.shape"
      ],
      "metadata": {
        "id": "lARwuHTKaO7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step6\n",
        "#Train-test split:\n",
        "from sklearn.model_selection import train_test_split\n",
        "(x_train,x_test,y_train,y_test)=train_test_split(x,y,test_size=0.4)\n",
        "x_train.shape\n",
        "y_train.shape\n",
        "x_test.shape\n",
        "y_test.shape\n"
      ],
      "metadata": {
        "id": "rczXhPS9aO9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step7\n",
        "#convert train to pandas df\n",
        "df1=pd.DataFrame(x_train)\n",
        "df1=df1.rename(columns={0:'news'})\n",
        "df2=pd.DataFrame(y_train)\n",
        "df2=df2.rename(columns={0:'sentiment'})\n",
        "df_train=pd.concat([df1,df2],axis=1)\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "U_DcgC5SaO_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert test to pandas df\n",
        "df3=pd.DataFrame(x_test)\n",
        "df3=df3.rename(columns={0:'news'})\n",
        "df4=pd.DataFrame(y_test)\n",
        "df4=df2.rename(columns={0:'sentiment'})\n",
        "df_test=pd.concat([df3,df4],axis=1)\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "WvGmD8H-aPE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step8 \n",
        "#Basic pre-processing of train and test data\n",
        "#punktuatsion xatolarni olib tashlaymiz\n",
        "import string\n",
        "string.punctuation\n",
        "\n",
        "def remove_punctuation(text):\n",
        "  if(type(text)==float):\n",
        "    return text\n",
        "  ans=\"\"  \n",
        "  for i in text:     \n",
        "    if i not in string.punctuation:\n",
        "      ans+=i    \n",
        "  return ans\n",
        "\n",
        "  df_train['news']= df_train['news'].apply(lambda x:remove_punctuation(x))\n",
        "df_test['news']= df_test['news'].apply(lambda x:remove_punctuation(x))\n",
        "\n",
        "df_train.head()\n",
        "#xatolar news column dan o'chirib tashlandi"
      ],
      "metadata": {
        "id": "gFFww45ccrxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step9\n",
        "#Ana endi biz stop word larni olib tashlaymiz\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "#keyingisida bir daniga foydalanamiz"
      ],
      "metadata": {
        "id": "tvgnYoZHcr0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step10\n",
        "#n-gram larni generate qilish\n",
        "def generate_N_grams(text,ngram=1):\n",
        "  words=[word for word in text.split(\" \") if word not in set(stopwords.words('english'))]  \n",
        "  print(\"Sentence after removing stopwords:\",words)\n",
        "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
        "  ans=[' '.join(ngram) for ngram in temp]\n",
        "  return ans\n",
        "  \n",
        "  generate_N_grams(\"The sun rises in the east\",2)"
      ],
      "metadata": {
        "id": "QRmbTsgTcr5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step11\n",
        "#Creating Unigrams\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def generate_N_grams(text,ngram=1):\n",
        "  words=[word for word in text.split(\" \") if word not in set(stopwords.words('english'))]  \n",
        "  print(\"Sentence after removing stopwords:\",words)\n",
        "  temp=zip(*[words[i:] for i in range(0,ngram)])\n",
        "  ans=[' '.join(ngram) for ngram in temp]\n",
        "  return ans\n",
        "  \n",
        "  generate_N_grams(\"The sun rises in the east\",2)\n",
        "\n",
        "\n",
        "from collections import defaultdict     #<<< Creating UNIGRAMS\n",
        "\n",
        "positiveValues=defaultdict(int)\n",
        "negativeValues=defaultdict(int)\n",
        "neutralValues=defaultdict(int)\n",
        "\n",
        "for text in df_train[df_train.sentiment==\"positive\"].news:\n",
        "  for word in generate_N_grams(text):\n",
        "    positiveValues[word]+=1\n",
        "\n",
        "for text in df_train[df_train.sentiment==\"negative\"].news:\n",
        "  for word in generate_N_grams(text):\n",
        "    negativeValues[word]+=1\n",
        "\n",
        "for text in df_train[df_train.sentiment==\"neutral\"].news:\n",
        "  for word in generate_N_grams(text):\n",
        "    neutralValues[word]+=1\n",
        "\n",
        "df_positive=pd.DataFrame(sorted(positiveValues.items(),key=lambda x:x[1],reverse=True))\n",
        "df_negative=pd.DataFrame(sorted(negativeValues.items(),key=lambda x:x[1],reverse=True))\n",
        "df_neutral=pd.DataFrame(sorted(neutralValues.items(),key=lambda x:x[1],reverse=True))\n",
        "\n",
        "pd1=df_positive[0][:10]\n",
        "pd2=df_positive[1][:10]\n",
        "\n",
        "ned1=df_negative[0][:10]\n",
        "ned2=df_negative[1][:10]\n",
        "\n",
        "nud1=df_neutral[0][:10]\n",
        "nud2=df_neutral[1][:10]\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "plt.bar(pd1,pd2, color ='green',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Words in positive dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in positive dataframe-UNIGRAM ANALYSIS\")\n",
        "plt.savefig(\"positive-unigram.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "plt.bar(ned1,ned2, color ='red',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Words in negative dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in negative dataframe-UNIGRAM ANALYSIS\")\n",
        "plt.savefig(\"negative-unigram.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "plt.bar(nud1,nud2, color ='yellow',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Words in neutral dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in neutral dataframe-UNIGRAM ANALYSIS\")\n",
        "plt.savefig(\"neutral-unigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PpAdHNf2cr8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step11\n",
        "#Creating Bigrams\n",
        "\n",
        "positiveValues2=defaultdict(int)\n",
        "negativeValues2=defaultdict(int)\n",
        "neutralValues2=defaultdict(int)\n",
        "\n",
        "for text in df_train[df_train.sentiment==\"positive\"].news:\n",
        "  for word in generate_N_grams(text,2):\n",
        "    positiveValues2[word]+=1\n",
        "\n",
        "for text in df_train[df_train.sentiment==\"negative\"].news:\n",
        "  for word in generate_N_grams(text,2):\n",
        "    negativeValues2[word]+=1\n",
        "\n",
        "for text in df_train[df_train.sentiment==\"neutral\"].news:\n",
        "  for word in generate_N_grams(text,2):\n",
        "    neutralValues2[word]+=1\n",
        "\n",
        "df_positive2=pd.DataFrame(sorted(positiveValues2.items(),key=lambda x:x[1],reverse=True))\n",
        "df_negative2=pd.DataFrame(sorted(negativeValues2.items(),key=lambda x:x[1],reverse=True))\n",
        "df_neutral2=pd.DataFrame(sorted(neutralValues2.items(),key=lambda x:x[1],reverse=True))\n",
        "\n",
        "pd1bi=df_positive2[0][:10]\n",
        "pd2bi=df_positive2[1][:10]\n",
        "\n",
        "ned1bi=df_negative2[0][:10]\n",
        "ned2bi=df_negative2[1][:10]\n",
        "\n",
        "nud1bi=df_neutral2[0][:10]\n",
        "nud2bi=df_neutral2[1][:10]\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "plt.bar(pd1bi,pd2bi, color ='green',width = 0.4)\n",
        "plt.xlabel(\"Words in positive dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in positive dataframe-BIGRAM ANALYSIS\")\n",
        "plt.savefig(\"positive-bigram.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "plt.bar(ned1bi,ned2bi, color ='red',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Words in negative dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in negative dataframe-BIGRAM ANALYSIS\")\n",
        "plt.savefig(\"negative-bigram.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "plt.bar(nud1bi,nud2bi, color ='yellow',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Words in neutral dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in neutral dataframe-BIGRAM ANALYSIS\")\n",
        "plt.savefig(\"neutral-bigram.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tz4B8Mg9cr_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step11\n",
        "#Creating Trigrams\n",
        "\n",
        "positiveValues3=defaultdict(int)\n",
        "negativeValues3=defaultdict(int)\n",
        "neutralValues3=defaultdict(int)\n",
        "\n",
        "for text in df_train[df_train.sentiment==\"positive\"].news:\n",
        "  for word in generate_N_grams(text,3):\n",
        "    positiveValues3[word]+=1\n",
        "\n",
        "for text in df_train[df_train.sentiment==\"negative\"].news:\n",
        "  for word in generate_N_grams(text,3):\n",
        "    negativeValues3[word]+=1\n",
        "\n",
        "for text in df_train[df_train.sentiment==\"neutral\"].news:\n",
        "  for word in generate_N_grams(text,3):\n",
        "    neutralValues3[word]+=1\n",
        "\n",
        "df_positive3=pd.DataFrame(sorted(positiveValues3.items(),key=lambda x:x[1],reverse=True))\n",
        "df_negative3=pd.DataFrame(sorted(negativeValues3.items(),key=lambda x:x[1],reverse=True))\n",
        "df_neutral3=pd.DataFrame(sorted(neutralValues3.items(),key=lambda x:x[1],reverse=True))\n",
        "\n",
        "pd1tri=df_positive3[0][:10]\n",
        "pd2tri=df_positive3[1][:10]\n",
        "\n",
        "ned1tri=df_negative3[0][:10]\n",
        "ned2tri=df_negative3[1][:10]\n",
        "\n",
        "nud1tri=df_neutral3[0][:10]\n",
        "nud2tri=df_neutral3[1][:10]\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "plt.bar(pd1tri,pd2tri, color ='green',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Words in positive dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in positive dataframe-TRIGRAM ANALYSIS\")\n",
        "plt.savefig(\"positive-trigram.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "plt.bar(ned1tri,ned2tri, color ='red',\n",
        "        width = 0.4) \n",
        "plt.xlabel(\"Words in negative dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in negative dataframe-TRIGRAM ANALYSIS\")\n",
        "plt.savefig(\"negative-trigram.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(1,figsize=(16,4))\n",
        "plt.bar(nud1tri,nud2tri, color ='yellow',\n",
        "        width = 0.4) \n",
        "plt.xlabel(\"Words in neutral dataframe\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 words in neutral dataframe-TRIGRAM ANALYSIS\")\n",
        "plt.savefig(\"neutral-trigram.png\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "q3FQ0czxf5rP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}